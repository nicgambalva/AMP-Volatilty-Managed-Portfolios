{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17ff6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main file for the implementation of volatility managed portfolios\n",
    "# As part of the Master Project for the Msc in Financial Engineering at EDHEC Buusiness School\n",
    "# Property of Wiktor Kotwicki, Moana Valdenaire, and Nicolas Gamboa Alvarez\n",
    "# EDHEC Business School, 2024-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "925e32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO's:\n",
    "# URGENTS:\n",
    "# Implement the support for FX and METALS (TODO: PX_BID and PX_ASK are not in the repository, I cannot do this until this is done)\n",
    "# Enhance the volatility managed portfolio construction: Tackle the issue of C\n",
    "# For both the Future and the Strategy classes, add functions that estimate the transaction costs for a transaction\n",
    "# Add a function to the Strategy class that estimates the most efficient transaction (i.e. if we rebalance, we don't sell all and then buy back, we buy or sell the difference)\n",
    "# Implement a GARCH estimator for the volatility within the Future class # TODO: Wiktor is doing this\n",
    "# Add estimations for only downside volatility\n",
    "# Implement also GMV and maybe Max Sharpe as possible benchmark strategies\n",
    "\n",
    "# 'Build the matrix'.\n",
    "# NUMBA optimization (make paralel portfolio_builder.py) First try with numba had several issues: DataFrames are not well supported and f-strings are not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e83f7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import portfolio_builder as pb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1905c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98ba2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_BID data for each index\n",
    "euroindex_GX1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/GX1_PX_BID.csv')\n",
    "euroindex_CF1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/CF1_PX_BID.csv')\n",
    "euroindex_AJ1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/AJ1_PX_BID.csv')\n",
    "euroindex_ST1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/ST1_PX_BID.csv')\n",
    "euroindex_EO1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/EO1_PX_BID.csv')\n",
    "euroindex_PP1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/PP1_PX_BID.csv')\n",
    "euroindex_IB1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/IB1_PX_BID.csv')\n",
    "euroindex_BE1_PX_BID = pd.read_csv('data_csv/indices/PX_BID/BE1_PX_BID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf0c3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_ASK data for each index\n",
    "euroindex_GX1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/GX1_PX_ASK.csv')\n",
    "euroindex_CF1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/CF1_PX_ASK.csv')\n",
    "euroindex_AJ1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/AJ1_PX_ASK.csv')\n",
    "euroindex_ST1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/ST1_PX_ASK.csv')\n",
    "euroindex_EO1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/EO1_PX_ASK.csv')\n",
    "euroindex_PP1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/PP1_PX_ASK.csv')\n",
    "euroindex_IB1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/IB1_PX_ASK.csv')\n",
    "euroindex_BE1_PX_ASK = pd.read_csv('data_csv/indices/PX_ASK/BE1_PX_ASK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "896fd1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_SETTLE data for each index\n",
    "euroindex_GX1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/GX1_PX_SETTLE.csv')\n",
    "euroindex_CF1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/CF1_PX_SETTLE.csv')\n",
    "euroindex_AJ1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/AJ1_PX_SETTLE.csv')\n",
    "euroindex_ST1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/ST1_PX_SETTLE.csv')\n",
    "euroindex_EO1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/EO1_PX_SETTLE.csv')\n",
    "euroindex_PP1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/PP1_PX_SETTLE.csv')\n",
    "euroindex_IB1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/IB1_PX_SETTLE.csv')\n",
    "euroindex_BE1_PX_SETTLE = pd.read_csv('data_csv/indices/PX_SETTLE/BE1_PX_SETTLE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0567dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_BID data for each metal\n",
    "metal_GC1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/GC1_PX_BID.csv')\n",
    "metal_SI1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/SI1_PX_BID.csv')\n",
    "# metal_LN1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/LN1_PX_BID.csv')\n",
    "# metal_LX1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/LX1_PX_BID.csv')\n",
    "# metal_LT1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/LT1_PX_BID.csv')\n",
    "# metal_LP1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/LP1_PX_BID.csv')\n",
    "# metal_LA1_PX_BID = pd.read_csv('data_csv/metals/PX_BID/LA1_PX_BID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf0a1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_ASK data for each metal\n",
    "metal_GC1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/GC1_PX_ASK.csv')\n",
    "metal_SI1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/SI1_PX_ASK.csv')\n",
    "# metal_LN1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/LN1_PX_ASK.csv')\n",
    "# metal_LX1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/LX1_PX_ASK.csv')\n",
    "# metal_LT1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/LT1_PX_ASK.csv')\n",
    "# metal_LP1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/LP1_PX_ASK.csv')\n",
    "# metal_LA1_PX_ASK = pd.read_csv('data_csv/metals/PX_ASK/LA1_PX_ASK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39be7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PX_SETTLE data for each metal\n",
    "metal_GC1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/GC1_PX_SETTLE.csv')\n",
    "metal_SI1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/SI1_PX_SETTLE.csv')\n",
    "# metal_LN1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/LN1_PX_SETTLE.csv')\n",
    "# metal_LX1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/LX1_PX_SETTLE.csv')\n",
    "# metal_LT1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/LT1_PX_SETTLE.csv')\n",
    "# metal_LP1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/LP1_PX_SETTLE.csv')\n",
    "# metal_LA1_PX_SETTLE = pd.read_csv('data_csv/metals/PX_SETTLE/LA1_PX_SETTLE.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88ef95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all the imported dataframes\n",
    "dataframes = [\n",
    "    euroindex_GX1_PX_BID,\n",
    "    euroindex_CF1_PX_BID,\n",
    "    euroindex_AJ1_PX_BID,\n",
    "    euroindex_ST1_PX_BID,\n",
    "    euroindex_EO1_PX_BID,\n",
    "    euroindex_PP1_PX_BID,\n",
    "    euroindex_IB1_PX_BID,\n",
    "    euroindex_BE1_PX_BID,\n",
    "    euroindex_GX1_PX_ASK,\n",
    "    euroindex_CF1_PX_ASK,\n",
    "    euroindex_AJ1_PX_ASK,\n",
    "    euroindex_ST1_PX_ASK,\n",
    "    euroindex_EO1_PX_ASK,\n",
    "    euroindex_PP1_PX_ASK,\n",
    "    euroindex_IB1_PX_ASK,\n",
    "    euroindex_BE1_PX_ASK,\n",
    "    euroindex_GX1_PX_SETTLE,\n",
    "    euroindex_CF1_PX_SETTLE,\n",
    "    euroindex_AJ1_PX_SETTLE,\n",
    "    euroindex_ST1_PX_SETTLE,\n",
    "    euroindex_EO1_PX_SETTLE,\n",
    "    euroindex_PP1_PX_SETTLE,\n",
    "    euroindex_IB1_PX_SETTLE,\n",
    "    euroindex_BE1_PX_SETTLE,\n",
    "    metal_GC1_PX_BID,\n",
    "    metal_SI1_PX_BID,\n",
    "    metal_GC1_PX_ASK,\n",
    "    metal_SI1_PX_ASK,\n",
    "    metal_GC1_PX_SETTLE,\n",
    "    metal_SI1_PX_SETTLE\n",
    "]\n",
    "\n",
    "dataframes_PX_SETTLE = [\n",
    "    euroindex_GX1_PX_SETTLE,\n",
    "    euroindex_CF1_PX_SETTLE,\n",
    "    euroindex_AJ1_PX_SETTLE,\n",
    "    euroindex_ST1_PX_SETTLE,\n",
    "    euroindex_EO1_PX_SETTLE,\n",
    "    euroindex_PP1_PX_SETTLE,\n",
    "    euroindex_IB1_PX_SETTLE,\n",
    "    euroindex_BE1_PX_SETTLE,\n",
    "    metal_GC1_PX_SETTLE,\n",
    "    metal_SI1_PX_SETTLE\n",
    "]\n",
    "\n",
    "dataframes_PX_BID = [\n",
    "    euroindex_GX1_PX_BID,\n",
    "    euroindex_CF1_PX_BID,\n",
    "    euroindex_AJ1_PX_BID,\n",
    "    euroindex_ST1_PX_BID,\n",
    "    euroindex_EO1_PX_BID,\n",
    "    euroindex_PP1_PX_BID,\n",
    "    euroindex_IB1_PX_BID,\n",
    "    euroindex_BE1_PX_BID,\n",
    "    metal_GC1_PX_BID,\n",
    "    metal_SI1_PX_BID\n",
    "]\n",
    "\n",
    "dataframes_PX_ASK = [\n",
    "    euroindex_GX1_PX_ASK,\n",
    "    euroindex_CF1_PX_ASK,\n",
    "    euroindex_AJ1_PX_ASK,\n",
    "    euroindex_ST1_PX_ASK,\n",
    "    euroindex_EO1_PX_ASK,\n",
    "    euroindex_PP1_PX_ASK,\n",
    "    euroindex_IB1_PX_ASK,\n",
    "    euroindex_BE1_PX_ASK,\n",
    "    metal_GC1_PX_ASK,\n",
    "    metal_SI1_PX_ASK\n",
    "]\n",
    "\n",
    "dataframes_euroindex = [\n",
    "    euroindex_GX1_PX_BID,\n",
    "    euroindex_CF1_PX_BID,\n",
    "    euroindex_AJ1_PX_BID,\n",
    "    euroindex_ST1_PX_BID,\n",
    "    euroindex_EO1_PX_BID,\n",
    "    euroindex_PP1_PX_BID,\n",
    "    euroindex_IB1_PX_BID,\n",
    "    euroindex_BE1_PX_BID,\n",
    "    euroindex_GX1_PX_ASK,\n",
    "    euroindex_CF1_PX_ASK,\n",
    "    euroindex_AJ1_PX_ASK,\n",
    "    euroindex_ST1_PX_ASK,\n",
    "    euroindex_EO1_PX_ASK,\n",
    "    euroindex_PP1_PX_ASK,\n",
    "    euroindex_IB1_PX_ASK,\n",
    "    euroindex_BE1_PX_ASK,\n",
    "    euroindex_GX1_PX_SETTLE,\n",
    "    euroindex_CF1_PX_SETTLE,\n",
    "    euroindex_AJ1_PX_SETTLE,\n",
    "    euroindex_ST1_PX_SETTLE,\n",
    "    euroindex_EO1_PX_SETTLE,\n",
    "    euroindex_PP1_PX_SETTLE,\n",
    "    euroindex_IB1_PX_SETTLE,\n",
    "    euroindex_BE1_PX_SETTLE\n",
    "]\n",
    "\n",
    "dataframes_metal = [\n",
    "    metal_GC1_PX_BID,\n",
    "    metal_SI1_PX_BID,\n",
    "    metal_GC1_PX_ASK,\n",
    "    metal_SI1_PX_ASK,\n",
    "    metal_GC1_PX_SETTLE,\n",
    "    metal_SI1_PX_SETTLE\n",
    "]\n",
    "\n",
    "dataframes_metal_BID = [\n",
    "    metal_GC1_PX_BID,\n",
    "    metal_SI1_PX_BID\n",
    "]\n",
    "\n",
    "dataframes_metal_ASK = [\n",
    "    metal_GC1_PX_ASK,\n",
    "    metal_SI1_PX_ASK\n",
    "]\n",
    "\n",
    "dataframes_metal_SETTLE = [\n",
    "    metal_GC1_PX_SETTLE,\n",
    "    metal_SI1_PX_SETTLE\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "232323a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the dataframes\n",
    "for df in dataframes:\n",
    "    try:\n",
    "        df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "        df.set_index('DATE', inplace=True)\n",
    "        df.drop(df.index[0], inplace=True)\n",
    "        df.replace('#N/A N/A', np.nan, inplace=True)\n",
    "        \n",
    "        # Now convert the columns to numeric values\n",
    "        df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "    except KeyError:\n",
    "        print(f\"KeyError: 'DATE' column not found in {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "175d0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For european indices, we get the values of the underlying indices (PX_LAST)\n",
    "euroindex_SPOT_LAST = pd.read_csv('data_csv/indices/PX_LAST/euroindex_SPOT_LAST.csv')\n",
    "euroindex_SPOT_LAST = pb.preprocess_data(euroindex_SPOT_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c6f286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the values for the fx rates\n",
    "fx_eurusd_PX_BID = pd.read_csv('data_csv/fx/EURUSD_PX_BID.csv')\n",
    "fx_eurusd_PX_ASK = pd.read_csv('data_csv/fx/EURUSD_PX_ASK.csv')\n",
    "fx_eurusd_PX_LAST = pd.read_csv('data_csv/fx/EURUSD_PX_LAST.csv')\n",
    "\n",
    "# We set DATE as index and drop the first row\n",
    "# If there's nothing in the index, we don't include the row\n",
    "fx_eurusd_PX_BID['DATE'] = pd.to_datetime(fx_eurusd_PX_BID['DATE'])\n",
    "fx_eurusd_PX_BID.set_index('DATE', inplace=True)\n",
    "fx_eurusd_PX_BID.drop(fx_eurusd_PX_BID.index[0], inplace=True)\n",
    "fx_eurusd_PX_BID.replace('#N/A N/A', np.nan, inplace=True)\n",
    "fx_eurusd_PX_BID.dropna(inplace=True)\n",
    "fx_eurusd_PX_ASK['DATE'] = pd.to_datetime(fx_eurusd_PX_ASK['DATE'])\n",
    "fx_eurusd_PX_ASK.set_index('DATE', inplace=True)\n",
    "fx_eurusd_PX_ASK.drop(fx_eurusd_PX_ASK.index[0], inplace=True)\n",
    "fx_eurusd_PX_ASK.replace('#N/A N/A', np.nan, inplace=True)\n",
    "fx_eurusd_PX_ASK.dropna(inplace=True)\n",
    "fx_eurusd_PX_LAST['DATE'] = pd.to_datetime(fx_eurusd_PX_LAST['DATE'])\n",
    "fx_eurusd_PX_LAST.set_index('DATE', inplace=True)\n",
    "fx_eurusd_PX_LAST.drop(fx_eurusd_PX_LAST.index[0], inplace=True)\n",
    "fx_eurusd_PX_LAST.replace('#N/A N/A', np.nan, inplace=True)\n",
    "fx_eurusd_PX_LAST.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc1ba399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build the Currency object:\n",
    "fx_eurusd = pb.Currency(\n",
    "    name='EURUSD',\n",
    "    base_currency='EUR',\n",
    "    quote_currency='USD',\n",
    "    px_bid=fx_eurusd_PX_BID['EURUSD Curncy'],\n",
    "    px_ask=fx_eurusd_PX_ASK['EURUSD Curncy'],\n",
    "    px_last=fx_eurusd_PX_LAST['EURUSD Curncy']\n",
    ")\n",
    "\n",
    "fx_usdeur = pb.Currency(\n",
    "    name='USDEUR',\n",
    "    base_currency='USD',\n",
    "    quote_currency='EUR',\n",
    "    px_bid=fx_eurusd_PX_BID['USDEUR Curncy'],\n",
    "    px_ask=fx_eurusd_PX_ASK['USDEUR Curncy'],\n",
    "    px_last=fx_eurusd_PX_LAST['USDEUR Curncy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80fd07e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FX: EURUSD, Base Currency: EUR, Quote Currency: USD, Start Date: 2000-03-15 00:00:00, Last Trade Date: 2025-04-09 00:00:00"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_eurusd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82d30001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FX: USDEUR, Base Currency: USD, Quote Currency: EUR, Start Date: 2000-03-15 00:00:00, Last Trade Date: 2025-04-09 00:00:00"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_usdeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04b68155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking in all PX_BID dataframes if there are any dupicate indexes\n",
    "for df in dataframes_PX_BID:\n",
    "    duplicates = []\n",
    "    for index in df.index:\n",
    "        if df.index.duplicated().any():\n",
    "            duplicates.append(index)\n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"Duplicates found in {df}: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8cd1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making one joint PX_SETTLE, one joint PX_BID and one joint PX_ASK dataframe\n",
    "# Ensuring all dataframes have unique index values before concatenation\n",
    "for df_list in [dataframes_PX_SETTLE, dataframes_PX_BID, dataframes_PX_ASK]:\n",
    "\tfor df in df_list:\n",
    "\t\tif df.index.duplicated().any():\n",
    "\t\t\tdf.reset_index(inplace=True)\n",
    "\t\t\tdf.drop_duplicates(subset='DATE', keep='last', inplace=True)\n",
    "\t\t\tdf.set_index('DATE', inplace=True)\n",
    "\n",
    "euroindex_PX_SETTLE = pd.concat(dataframes_PX_SETTLE, axis=1)\n",
    "euroindex_PX_BID = pd.concat(dataframes_PX_BID, axis=1)\n",
    "euroindex_PX_ASK = pd.concat(dataframes_PX_ASK, axis=1)\n",
    "\n",
    "# Now for the metals\n",
    "for df_list in [dataframes_metal_SETTLE, dataframes_metal_BID, dataframes_metal_ASK]:\n",
    "\tfor df in df_list:\n",
    "\t\tif df.index.duplicated().any():\n",
    "\t\t\tdf.reset_index(inplace=True)\n",
    "\t\t\tdf.drop_duplicates(subset='DATE', keep='last', inplace=True)\n",
    "\t\t\tdf.set_index('DATE', inplace=True)\n",
    "metals_PX_SETTLE = pd.concat(dataframes_metal_SETTLE, axis=1)\n",
    "metals_PX_BID = pd.concat(dataframes_metal_BID, axis=1)\n",
    "metals_PX_ASK = pd.concat(dataframes_metal_ASK, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f142096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the calendar\n",
    "calendar = {}\n",
    "for future in pb.FUTURES_EURO_INDICES.values():\n",
    "    calendar[future] = pd.read_csv(f'data_csv/calendars/{future}.csv')\n",
    "    calendar[future]['Last Trade'] = pd.to_datetime(calendar[future]['Last Trade'])\n",
    "    calendar[future]['First Notice'] = pd.to_datetime(calendar[future]['First Notice'])\n",
    "    calendar[future]['Last Delivery'] = pd.to_datetime(calendar[future]['First Delivery'])\n",
    "    calendar[future]['Last Delivery'] = pd.to_datetime(calendar[future]['Last Delivery'])\n",
    "    calendar[future].set_index('Ticker', inplace=True)\n",
    "\n",
    "for future in pb.SUPPORTED_METALS.values():\n",
    "    calendar[future] = pd.read_csv(f'data_csv/calendars/{future}.csv')\n",
    "    calendar[future]['Last Trade'] = pd.to_datetime(calendar[future]['Last Trade'])\n",
    "    calendar[future]['First Notice'] = pd.to_datetime(calendar[future]['First Notice'])\n",
    "    calendar[future]['Last Delivery'] = pd.to_datetime(calendar[future]['First Delivery'])\n",
    "    calendar[future]['Last Delivery'] = pd.to_datetime(calendar[future]['Last Delivery'])\n",
    "    calendar[future].set_index('Ticker', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c27e24b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing contracts: []\n"
     ]
    }
   ],
   "source": [
    "# Checking if all the futures (indexes in the calendars) are in the columns of the dataframes\n",
    "all_euroindices_contracts = []\n",
    "missing_contracts = []\n",
    "for df in dataframes_euroindex:\n",
    "    all_euroindices_contracts += df.columns.tolist()\n",
    "all_euroindices_contracts = list(set(all_euroindices_contracts))\n",
    "\n",
    "# Dropping 'DATE'\n",
    "all_euroindices_contracts = [contract for contract in all_euroindices_contracts if contract != 'DATE']\n",
    "\n",
    "for future in calendar.keys():\n",
    "    if future not in all_euroindices_contracts:\n",
    "        missing_contracts.append(future)\n",
    "        \n",
    "missing_contracts = [future for future in missing_contracts if future not in pb.FUTURES_EURO_INDICES.values()]\n",
    "missing_contracts = [future for future in missing_contracts if future not in pb.SUPPORTED_METALS.values()]\n",
    "all_euroindices_contracts = [contract for contract in all_euroindices_contracts if contract not in pb.FUTURES_EURO_INDICES.values()]\n",
    "print(f\"Missing contracts: {missing_contracts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff161d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing contracts: []\n"
     ]
    }
   ],
   "source": [
    "# Now for metals\n",
    "all_metals_contracts = []\n",
    "missing_contracts = []\n",
    "for df in dataframes_metal:\n",
    "    all_metals_contracts += df.columns.tolist()\n",
    "all_metals_contracts = list(set(all_metals_contracts))\n",
    "\n",
    "# Dropping 'DATE'\n",
    "all_metals_contracts = [contract for contract in all_metals_contracts if contract != 'DATE']\n",
    "\n",
    "for future in calendar.keys():\n",
    "    if future not in all_metals_contracts:\n",
    "        missing_contracts.append(future)\n",
    "        \n",
    "missing_contracts = [future for future in missing_contracts if future not in pb.SUPPORTED_METALS.values()]\n",
    "missing_contracts = [future for future in missing_contracts if future not in pb.FUTURES_EURO_INDICES.values()]\n",
    "all_metals_contracts = [contract for contract in all_metals_contracts if contract not in pb.SUPPORTED_METALS.values()]\n",
    "print(f\"Missing contracts: {missing_contracts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b7ff895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsuccessful Euroindex contracts: []\n",
      "Unsuccessful metals contracts: []\n"
     ]
    }
   ],
   "source": [
    "# For each contract, we will check the data in settle\n",
    "# In order to create a new column in the calendar dataframe\n",
    "# With the start date of the contract\n",
    "for contract in all_euroindices_contracts:\n",
    "    unsuccessful = []\n",
    "    future = pb.identify_future(contract)\n",
    "    if future is None:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "    try:\n",
    "        euroindex_PX_SETTLE[contract].dropna(inplace=True)\n",
    "        euroindex_PX_SETTLE.sort_index(inplace=True)\n",
    "        first_date = euroindex_PX_SETTLE[contract].first_valid_index()\n",
    "        calendar[future].loc[contract, 'Start Date'] = first_date\n",
    "    except KeyError:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "print(f\"Unsuccessful Euroindex contracts: {unsuccessful}\")\n",
    "\n",
    "for contract in all_metals_contracts:\n",
    "    unsuccessful = []\n",
    "    future = pb.identify_future(contract)\n",
    "    if future is None:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "    try:\n",
    "        metals_PX_SETTLE[contract].dropna(inplace=True)\n",
    "        metals_PX_SETTLE.sort_index(inplace=True)\n",
    "        first_date = metals_PX_SETTLE[contract].first_valid_index()\n",
    "        calendar[future].loc[contract, 'Start Date'] = first_date\n",
    "    except KeyError:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "print(f\"Unsuccessful metals contracts: {unsuccessful}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97810a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsuccessful Euroindex contracts: []\n",
      "Unsuccessful metals contracts: []\n"
     ]
    }
   ],
   "source": [
    "# For all contract, we loop through all dfs\n",
    "# If the contract is in the dataframe, we use the calendar\n",
    "# All the prices after the last trade date are set as pd.nan\n",
    "unsuccessful = []\n",
    "for contract in all_euroindices_contracts:\n",
    "    try:\n",
    "        for df in dataframes:\n",
    "            if contract in df.columns:\n",
    "                column = df[contract]\n",
    "                last_trade_date = calendar[pb.identify_future(contract)].loc[contract, 'Last Trade']\n",
    "                column.loc[column.index > last_trade_date] = np.nan\n",
    "                df[contract] = column\n",
    "        # Now for euroindex settle\n",
    "        column = euroindex_PX_SETTLE[contract]\n",
    "        last_trade_date = calendar[pb.identify_future(contract)].loc[contract, 'Last Trade']\n",
    "        column.loc[column.index > last_trade_date] = np.nan\n",
    "        euroindex_PX_SETTLE[contract] = column\n",
    "    except:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "print(f\"Unsuccessful Euroindex contracts: {unsuccessful}\")\n",
    "\n",
    "# Now for metals\n",
    "for contract in all_metals_contracts:\n",
    "    try:\n",
    "        for df in dataframes:\n",
    "            if contract in df.columns:\n",
    "                column = df[contract]\n",
    "                last_trade_date = calendar[pb.identify_future(contract)].loc[contract, 'Last Trade']\n",
    "                column.loc[column.index > last_trade_date] = np.nan\n",
    "                df[contract] = column\n",
    "        # Now for metals settle\n",
    "        column = metals_PX_SETTLE[contract]\n",
    "        last_trade_date = calendar[pb.identify_future(contract)].loc[contract, 'Last Trade']\n",
    "        column.loc[column.index > last_trade_date] = np.nan\n",
    "        metals_PX_SETTLE[contract] = column\n",
    "    except:\n",
    "        unsuccessful.append(contract)\n",
    "        continue\n",
    "print(f\"Unsuccessful metals contracts: {unsuccessful}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa8b19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating the unsuccessful contracts from the dataframes\n",
    "for contract in unsuccessful:\n",
    "    if contract in all_metals_contracts:\n",
    "        all_metals_contracts.remove(contract)\n",
    "    if contract in all_euroindices_contracts:\n",
    "        all_euroindices_contracts.remove(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41eac8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: AJH6 Index not found in dataframes - 'AJH6 Index'\n",
      "Contracts not done: ['AJH6 Index']\n",
      "Contracts done: 1858\n"
     ]
    }
   ],
   "source": [
    "# Building all the contracts and futures for euroindices\n",
    "contracts_euroindex = {}\n",
    "contracts_not_done = []\n",
    "\n",
    "for contract in all_euroindices_contracts:\n",
    "    try:\n",
    "        # Identify the future name\n",
    "        future_name = pb.identify_future(contract)\n",
    "        if future_name is None:\n",
    "            raise ValueError(f\"Future name not found for contract {contract}\")\n",
    "\n",
    "        # Get the px_settle, px_bid, px_ask, and underlying data\n",
    "        px_settle = euroindex_PX_SETTLE[contract]\n",
    "        px_bid = euroindex_PX_BID[contract]\n",
    "        px_ask = euroindex_PX_ASK[contract]\n",
    "        underlying = euroindex_SPOT_LAST[future_name]\n",
    "\n",
    "        # Create the contract\n",
    "        contracts_euroindex[contract] = pb.Contract(\n",
    "            name=contract,\n",
    "            type='INDEX',\n",
    "            currency='EUR',\n",
    "            calendar=calendar,\n",
    "            px_settle=px_settle,\n",
    "            px_bid=px_bid,\n",
    "            px_ask=px_ask,\n",
    "            underlying_data=underlying\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {contract} not found in dataframes - {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {contract}: {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "\n",
    "print(f\"Contracts not done: {contracts_not_done}\")\n",
    "print(f\"Contracts done: {len(contracts_euroindex)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "148347aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building all the contracts and futures for metals\n",
    "contracts_metal = {}\n",
    "contracts_not_done = []\n",
    "\n",
    "for contract in all_metals_contracts:\n",
    "    try:\n",
    "        # Identify the future name\n",
    "        future_name = pb.identify_future(contract)\n",
    "        if future_name is None:\n",
    "            raise ValueError(f\"Future name not found for contract {contract}\")\n",
    "\n",
    "        # Get the px_settle, px_bid, px_ask, and underlying data\n",
    "        px_settle = metals_PX_SETTLE[contract]\n",
    "        px_bid = metals_PX_BID[contract]\n",
    "        px_ask = metals_PX_ASK[contract]\n",
    "\n",
    "        # Create the contract\n",
    "        contracts_metal[contract] = pb.Contract(\n",
    "            name=contract,\n",
    "            type='METAL',\n",
    "            currency='USD',\n",
    "            calendar=calendar,\n",
    "            px_settle=px_settle,\n",
    "            px_bid=px_bid,\n",
    "            px_ask=px_ask\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {contract} not found in dataframes - {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {contract}: {e}\")\n",
    "        contracts_not_done.append(contract)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db446923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a dictionary with all the contracts, divided by the underlying\n",
    "contracts_euroindex_by_underlying = {}\n",
    "for contract in contracts_euroindex.keys():\n",
    "    contract_name = contracts_euroindex[contract].name\n",
    "    underlying = contracts_euroindex[contract].underlying\n",
    "    if underlying not in contracts_euroindex_by_underlying:\n",
    "        contracts_euroindex_by_underlying[underlying] = []\n",
    "    contracts_euroindex_by_underlying[underlying].append(contract_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "faad41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the metals\n",
    "contracts_metal_by_underlying = {}\n",
    "for contract in contracts_metal.keys():\n",
    "    contract_name = contracts_metal[contract].name\n",
    "    underlying = contracts_metal[contract].underlying\n",
    "    if underlying not in contracts_metal_by_underlying:\n",
    "        contracts_metal_by_underlying[underlying] = []\n",
    "    contracts_metal_by_underlying[underlying].append(contract_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3a6fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future IB1 Index created successfully.\n",
      "Roll of the future IB1 Index built successfully.\n",
      "Future CF1 Index created successfully.\n",
      "Roll of the future CF1 Index built successfully.\n",
      "Future EO1 Index created successfully.\n",
      "Roll of the future EO1 Index built successfully.\n",
      "Future PP1 Index created successfully.\n",
      "Roll of the future PP1 Index built successfully.\n",
      "Future BE1 Index created successfully.\n",
      "Roll of the future BE1 Index built successfully.\n",
      "Future AJ1 Index created successfully.\n",
      "Roll of the future AJ1 Index built successfully.\n",
      "Future GX1 Index created successfully.\n",
      "Roll of the future GX1 Index built successfully.\n",
      "Future ST1 Index created successfully.\n",
      "Roll of the future ST1 Index built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Build all futures - European indices (all vols except GARCH)\n",
    "futures_euroindex = []\n",
    "for underlying in contracts_euroindex_by_underlying.keys():\n",
    "    try:\n",
    "        contracts = contracts_euroindex_by_underlying[underlying]\n",
    "        future = pb.Future(\n",
    "            name=underlying,\n",
    "            type='INDEX',\n",
    "            currency='EUR',\n",
    "            calendar=calendar,\n",
    "            underlying_data=euroindex_SPOT_LAST[underlying],\n",
    "        )\n",
    "        print(f\"Future {underlying} created successfully.\")\n",
    "        for contract in contracts:\n",
    "            future.add_contract(contracts_euroindex[contract])\n",
    "        futures_euroindex.append(future)\n",
    "        try:\n",
    "            # Build roll and all classic vols, but skip GARCH\n",
    "            future.build_theoretical_roll_settle()\n",
    "            print(f\"Roll of the future {underlying} built successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while building the roll of the future {underlying}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {underlying} not found in dataframes - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {underlying}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0da85de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roll and realized vols for SI1 Comdty built successfully.\n",
      "Roll and realized vols for GC1 Comdty built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Build all futures - Metals (all vols except GARCH)\n",
    "futures_metals = []\n",
    "for underlying in contracts_metal_by_underlying.keys():\n",
    "    try:\n",
    "        contracts = contracts_metal_by_underlying[underlying]\n",
    "        future = pb.Future(\n",
    "            name=underlying,\n",
    "            type='METAL',\n",
    "            currency='USD',\n",
    "            calendar=calendar,\n",
    "            currency_object=fx_usdeur,\n",
    "        )\n",
    "        for contract in contracts:\n",
    "            future.add_contract(contracts_metal[contract])\n",
    "        futures_metals.append(future)\n",
    "        try:\n",
    "            # Build roll and all classic vols, but skip GARCH\n",
    "            future.build_theoretical_roll_settle()\n",
    "            print(f\"Roll and realized vols for {underlying} built successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while building the roll or realized vols of the future {underlying}: {e}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {underlying} not found in dataframes - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {underlying}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "513c3051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GARCH volatilities built for IB1 Index\n",
      "GARCH volatilities built for CF1 Index\n",
      "GARCH volatilities built for EO1 Index\n",
      "GARCH volatilities built for PP1 Index\n",
      "GARCH volatilities built for BE1 Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasgamboaalvarez/Documents/Projects/AMP-Volatilty-Managed-Portfolios/.venv/lib/python3.12/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\n",
      "Positive directional derivative for linesearch\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GARCH volatilities built for AJ1 Index\n",
      "GARCH volatilities built for GX1 Index\n",
      "GARCH volatilities built for ST1 Index\n"
     ]
    }
   ],
   "source": [
    "# Build GARCH volatilities for all futures (this may take a long time)\n",
    "# DO NOT RUN THIS DO NOT RUN THIS DO NOT RUN THIS DO NOT RUN THIS\n",
    "\n",
    "for future in futures_euroindex:\n",
    "    try:\n",
    "        future.build_garch_vols(step=10)\n",
    "        print(f\"GARCH volatilities built for {future.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while building GARCH vols for {future.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4567e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GARCH volatilities built for SI1 Comdty\n",
      "FX and base currency GARCH volatilities built for SI1 Comdty\n",
      "GARCH volatilities built for GC1 Comdty\n",
      "FX and base currency GARCH volatilities built for GC1 Comdty\n"
     ]
    }
   ],
   "source": [
    "# Build GARCH volatilities for all metals futures (this may take a long time)\n",
    "# DO NOT RUN THIS DO NOT RUN THIS DO NOT RUN THIS DO NOT RUN THIS\n",
    "\n",
    "for future in futures_metals:\n",
    "    try:\n",
    "        future.build_garch_vols(step=10)\n",
    "        print(f\"GARCH volatilities built for {future.name}\")\n",
    "        future.build_fx_and_base_currency_vols_garch(step=10)\n",
    "        print(f\"FX and base currency GARCH volatilities built for {future.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while building GARCH vols for {future.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8ae0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future IB1 Index saved successfully.\n",
      "Future CF1 Index saved successfully.\n",
      "Future EO1 Index saved successfully.\n",
      "Future PP1 Index saved successfully.\n",
      "Future BE1 Index saved successfully.\n",
      "Future AJ1 Index saved successfully.\n",
      "Future GX1 Index saved successfully.\n",
      "Future ST1 Index saved successfully.\n",
      "Future SI1 Comdty saved successfully.\n",
      "Future GC1 Comdty saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Saving the futures and contracts to a pickle file\n",
    "# Under 'outputs/futures'\n",
    "for future in futures_euroindex:\n",
    "    with open(f'outputs/futures/{future.name}.pkl', 'wb') as f:\n",
    "        pickle.dump(future, f)\n",
    "        print(f\"Future {future.name} saved successfully.\")\n",
    "for future in futures_metals:\n",
    "    with open(f'outputs/futures/{future.name}.pkl', 'wb') as f:\n",
    "        pickle.dump(future, f)\n",
    "        print(f\"Future {future.name} saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43e4fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Futures euroindex saved successfully.\n",
      "Futures metals saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save a list of objects\n",
    "with open('outputs/futures/futures_euroindex.pkl', 'wb') as f:\n",
    "    pickle.dump(futures_euroindex, f)\n",
    "    print(\"Futures euroindex saved successfully.\")\n",
    "with open('outputs/futures/futures_metals.pkl', 'wb') as f:\n",
    "    pickle.dump(futures_metals, f)\n",
    "    print(\"Futures metals saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
